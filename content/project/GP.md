+++
# Date this page was created.
date = 2016-04-27T00:00:00

# Project title.
title = "Gaussian Process Imputation Models"

# Project summary to display on homepage.
summary = "Understanding new approaches to old imputations problems"

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "GP_results.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["Methods"]

# Optional external URL for project (replaces project detail page).
#external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
#image = ""
#caption = ""

baseurl = "https://mgb-research.netlify.com/"
+++

I have become increasingly interested in the use of Gaussian process models as a tool for forecasting and imputation with univariate time series. See my [blog post](https://mgb-research.netlify.com/post/gaussian-process-imputation-models/) on the topic for more information and a toy forecasting problem. 

I am currently working on a study examining the effectiveness of these models in imputing heart rate data that has been severely corrupted by artifact - to the point that there is not "enough" true signal remaining to do much of anything with. 
