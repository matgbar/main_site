<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Gaussian Process Imputation/Forecast Models</title>
  <meta name="author" content="Matthew Barstead, Ph.D." />
  
  
  
  
  <meta name="keywords" content="R, R programming, Data Science, Statistics, Bayesian, Stan, Gaussian Process, Forecasting, Predictive Modeling, R-bloggers">
  
  
  <meta name="description" content="Musings on R, Statistics, Data Science, and Programming">

  <meta name="generator" content="Hugo 0.75.1" />

  
  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.11.2/css/all.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="/css/animate.css" rel="stylesheet">

  
  
    <link href="/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">
  

  
  <link href="/css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png" />

  
  <link href="/css/owl.carousel.css" rel="stylesheet">
  <link href="/css/owl.theme.css" rel="stylesheet">

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Dead Reckoning Analytics and Consulting">

  
  
  
  
  
  
  
  <meta property="og:locale" content="en_us">
  <meta property="og:site_name" content="Dead Reckoning Analytics and Consulting">
  <meta property="og:title" content="Gaussian Process Imputation/Forecast Models">
  <meta property="og:type" content="article">
  <meta property="og:url" content="/blog/2018/05/21/2018-05-21-gaussian-process-imputation-models/" />
  <meta property="og:description" content="Musings on R, Statistics, Data Science, and Programming">
  <meta property="og:image" content="/img/banners/gp-forecast-banner.png">
  <meta property="og:image:type" content="image/png">
  
  
  
    <meta property="og:image:width" content="1344">
    <meta property="og:image:height" content="960">
  
  
  <meta property="og:updated_time" content="2018-05-21T00:00:00Z">
  
    
    
    <meta property="article:section" content="77">
    <meta property="article:tag" content="Bayesian">
    <meta property="article:tag" content="Stan">
    <meta property="article:tag" content="R">
    <meta property="article:tag" content="Gaussian Process">
    <meta property="article:tag" content="Forecasting">
    <meta property="article:tag" content="Predictive Modeling">
    <meta property="article:tag" content="R-bloggers">
    
    
    <meta property="article:published_time" content="2018-05-21T00:00:00Z">
    <meta property="article:modified_time" content="2018-05-21T00:00:00Z">
  

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@dead_reck">
  <meta name="twitter:title" content="Gaussian Process Imputation/Forecast Models">
  
  <meta name="twitter:image" content="/img/banners/gp-forecast-banner.png">
  
  <meta name="twitter:description" content="Musings on R, Statistics, Data Science, and Programming">
  
  
  
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX&#45;AMS&#45;MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}}); </script>

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="/">
                    <img src="/img/logo-dead-8.png" height="49" width="241" alt="Gaussian Process Imputation/Forecast Models logo" class="hidden-xs hidden-sm">
                    <img src="/img/logo-dead-8.png" height="49" width="241" alt="Gaussian Process Imputation/Forecast Models logo" class="visible-xs visible-sm">
                    <span class="sr-only">Gaussian Process Imputation/Forecast Models - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fas fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  
                  <li class="dropdown active">
                    
                    <a href="/blog/">Blog</a>
                    
                  </li>
                  
                  
                  <li class="dropdown">
                    
                    <a href="/contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Gaussian Process Imputation/Forecast Models</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        
                          <p class="text-muted text-uppercase mb-small text-right">
                            By <a href="#">Matthew Barstead, Ph.D.</a>
                             | 
                            May 21, 2018
                          </p>
                        

                        <div id="post-content">
                          


<p>(Updated: 2020-12-24)</p>
<p>When would it not be good to have a way to forecast the future? Honestly, I lack the imagination to provide an answer, though I’ll admit there are likely edge cases I am not considering. But on average, all things being equal, it is better to know than to not know what is coming. For companies, the ability to accurately forecast events <em>is</em> the business model.</p>
<p>The simplest forecast model is one in which we use trends over time to predict future events, the assumption being that the previous trend will continue essentially as is through the forecast window. That seem like a simple forecast model, but the trick is what a given model represents as the “trend.” For some data, a linear model is going to make perfect sense:</p>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>For others, such a simple model is not going to be very effective.</p>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The linear model here alone is a not a particularly good fit, though there is clearly an average change over time. However, equally clear is that there is a seasonal pattern that is increasing in its magnitude over time. The linear model as defined in the plot above does not know how to handle such a pattern.</p>
<p>Let’s say the prediction challenge here is to forecast airline passengers in 1960 using only airline passenger data from the preceding years. We know a simple linear change over time approach is not going to work or at least is probably not our best model - though it is better than no model since it would at least capture the upward trend. Our only data here is a uni-dimensional time-series which means that our task is to effectively model associations between monthly airline passengers across time, using only what we can extract from existing patterns.</p>
<p>In an ideal world, we would want to take into account other properties that would affect air travel in a forecast model. Sometimes, the data are what they are and the single time series is all we have to work from. One thing I like about a Gaussian process approach is that, using fairly well-established covariance functions, we can take a layered approach. My general approach to model building is to move from the simple to complex. Because the sum of several Gaussian processes is itself a Gaussian process, we can simply add or remove any covariance functions that do not seem to useful in improving our forecast.</p>
<p>This is a hands-on approach. The model will learn the appropriate hyperparameters for the covariance function(s) from the data - provided the model is appropriate. So that part feels a little more like a machine learning model. However, which covariance functions to include, whether transformations of the data are beneficial, and how to define the covariance functions takes some trial an error.</p>
<p>So let’s dig into that trial and error phase. First, before we get started with any modeling, let’s split the data up into the training and test sets.</p>
<pre class="r"><code>air_pass_train &lt;- air_pass_tbl %&gt;% 
  filter(year &lt; 1960)

air_pass_test &lt;- air_pass_tbl %&gt;% 
  filter(year &gt;= 1960)</code></pre>
<p>In viewing the data I see at least three, maybe even four properties of the time series that I would like to capture in my model:</p>
<ol style="list-style-type: decimal">
<li>Over time there is an average increase in the number of passengers.</li>
<li>There is a seasonal trend on top of the average increase that appears to be annual in nature, which would make sense for the airline industry in then (and probably now - COVID crisis notwithstanding).</li>
<li>The effect of the seasonal trends is more pronounced over time</li>
<li>There <em>may</em>, and I stress <em>may</em> be a slight acceleration in the, long-term increase in monthly passengers</li>
</ol>
<p>So can I create a model that somehow accounts for all of these different features of the times series? To find out we start with the simplest model - one that can address the first point. This first model will use the squared exponential covariance function (below) to bake in the idea that time points closer together will have airline passenger values that are more similar than those that are farther apart. How close? How much of an effect of time will there be on the decay in covariance? That is where the modeling comes in. We use the data to tune the hyperparameters of the squared exponential covariance function.</p>
<p><span class="math display">\[k(t,t&#39;) = \sigma^2 exp\Big(-\frac{(t-t&#39;)^2}{2l_1^2}\Big)\]</span></p>
<p>where <span class="math inline">\(\sigma^2\)</span> is the estimated variance accounted for by the function <span class="math inline">\(k\)</span> and <span class="math inline">\(l\)</span> is a length scale parameter that governs the decay rate. So here <span class="math inline">\(\sigma^2\)</span> governs how much variance the function accounts for in the observed data and <span class="math inline">\(l\)</span> is our parameter most closely connected with the decay in the covariance between two points as a function of time.</p>
<p>Let’s get the data ready:</p>
<pre class="r"><code>m1_data &lt;- list(
  N1 = nrow(air_pass_train), 
  N2 = nrow(air_pass_test), 
  X = air_pass_train[[&#39;year&#39;]], 
  Y = air_pass_train[[&#39;pass&#39;]], 
  Xp = air_pass_test[[&#39;year&#39;]]
)</code></pre>
<p>The model variables are:
- <code>N1</code>: the number of observations in the prediction set
- <code>N2</code>: the number of observation in the test set
- <code>X</code>: evenly spaced interval - in this case time as measured in months
- <code>Y</code>: passengers in a given month
- <code>Xp</code>: the prediction window (which set of months/which time window to generate predicted passenger rates)</p>
<p>Now for the <code>Stan</code> code that translates this. I was inspired and borrowed from Nate Lemoine’s post on <a href="https://natelemoine.com/even-faster-gaussian-processes-in-stan/">Gaussian processes</a> when setting this model up. I highly recommend if readers are interested in gain additional exposure to this modeling approach.</p>
<pre class="stan"><code>functions{
    //covariance function for main portion of the model
    matrix main_GP(
        int Nx,
        vector x,
        int Ny,
        vector y, 
        real alpha1,
        real rho1){
                    matrix[Nx, Ny] Sigma;
    
                    //specifying random Gaussian process that governs covariance matrix
                    for(i in 1:Nx){
                        for (j in 1:Ny){
                            Sigma[i,j] = alpha1*exp(-square(x[i]-y[j])/2/square(rho1));
                        }
                    }
                    
                    return Sigma;
                }
    //function for posterior calculations
    vector post_pred_rng(
        real a1,
        real r1, 
        real sn,
        int No,
        vector xo,
        int Np, 
        vector xp,
        vector yobs){
                matrix[No,No] Ko;
                matrix[Np,Np] Kp;
                matrix[No,Np] Kop;
                matrix[Np,No] Ko_inv_t;
                vector[Np] mu_p;
                matrix[Np,Np] Tau;
                matrix[Np,Np] L2;
                vector[Np] yp;
    
    //--------------------------------------------------------------------
    //Kernel Multiple GPs for observed data
    Ko = main_GP(No, xo, No, xo, a1, r1);
    for(n in 1:No) Ko[n,n] += sn;
        
    //--------------------------------------------------------------------
    //kernel for predicted data
    Kp = main_GP(Np, xp, Np, xp,  a1, r1);
    for(n in 1:Np) Kp[n,n] += sn;
        
    //--------------------------------------------------------------------
    //kernel for observed and predicted cross 
    Kop = main_GP(No, xo, Np, xp,  a1, r1);
    
    //--------------------------------------------------------------------
    //Algorithm 2.1 of Rassmussen and Williams 
    Ko_inv_t = Kop&#39;/Ko;
    mu_p = Ko_inv_t*yobs;
    Tau=Kp-Ko_inv_t*Kop;
    L2 = cholesky_decompose(Tau);
    yp = mu_p + L2*rep_vector(normal_rng(0,1), Np);
    return yp;
    }
}

data { 
    int&lt;lower=1&gt; N1;
    int&lt;lower=1&gt; N2;
    vector[N1] X; 
    vector[N1] Y;
    vector[N2] Xp;
}

transformed data { 
    vector[N1] mu;
    for(n in 1:N1) mu[n] = 0;
}

parameters {
  // a1, r1, and sigma_sq cannot be negative 
    real&lt;lower=0&gt; a1;
    real&lt;lower=0&gt; r1;
    real&lt;lower=0&gt; sigma_sq;
}

model{ 
    matrix[N1,N1] Sigma;
    matrix[N1,N1] L_S;
    
    //using GP function from above 
    Sigma = main_GP(N1, X, N1, X,  a1, r1);
    for(n in 1:N1) Sigma[n,n] += sigma_sq;
    
    L_S = cholesky_decompose(Sigma);
    Y ~ multi_normal_cholesky(mu, L_S);
    
    // priors for parameters - effecitvely the upper half of the students t-distribution
    a1 ~ student_t(3,0,1);
    r1 ~ student_t(3,0,1);
    sigma_sq ~ student_t(3,0,1);
}

generated quantities {
    vector[N2] Ypred = post_pred_rng(a1, r1, sigma_sq, N1, X, N2, Xp, Y);
}</code></pre>
<p>And now for the actual model.</p>
<pre class="r"><code># Easier to note these upfront
m1_pars.to.monitor&lt;-c(&#39;a1&#39;,&#39;r1&#39;,&#39;sigma_sq&#39;, &#39;Ypred&#39;)

#Note that I have a machine at home with 12 logical cores and 64GB of RAM
m1 &lt;- stan(
  file = &#39;../../blog_code/gp_m1.stan&#39;,
  data = m1_data, 
  warmup = 1000,
  iter = 2000,
  refresh=1000,
  chains = 6,
  pars = m1_pars.to.monitor,
  control = list(adapt_delta = .95, 
                 max_treedepth = 10), 
  seed = 20030414
)</code></pre>
<p>The model will converge, though there is some evidence that not all is well. Still, the traceplots below suggest the distributions of the model parameters converged reasonably well (a few spikes I don’t love). I often use more chains when modeling building to help with diagnosis problems if they arise. Three chains should be sufficient for most models.</p>
<pre class="r"><code>traceplot(m1, pars=c(&#39;a1&#39;, &#39;r1&#39;, &#39;sigma_sq&#39;))</code></pre>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Predicted values are about as good as we saw with the linear regression model, and the credibility envelope misses the two highest values in 1960 altogether.</p>
<pre class="r"><code>g_m1 &lt;-
brms::posterior_samples(m1, &#39;Ypred&#39;) %&gt;% 
  as.data.frame() %&gt;% 
  pivot_longer(cols = starts_with(&#39;Ypred&#39;), values_to = &#39;pass&#39;) %&gt;% 
  mutate(
    year = rep(air_pass_test[[&#39;year&#39;]], 6000)
  ) %&gt;%
  ggplot(aes(x = year, y = pass)) +
  stat_lineribbon(color = &quot;#08519C&quot;, fill = &#39;#426EBD&#39;, lwd = .5, .width = .95, alpha = .7) +
  geom_point(data = air_pass_test, aes(x = year, y = pass)) +
  geom_line(data = air_pass_test, aes(x = year, y = pass)) +
  labs(x = &quot;Month in 1960&quot;, y = &quot;Passengers (in thousands)&quot;, 
       caption = &#39;Model 1. Single Gaussian process model on raw passenger totals.&#39;) +
    scale_x_continuous(breaks = c(1960, 1960.25, 1960.5, 1960.75), 
                     labels = c(&#39;Jan&#39;, &#39;Apr&#39;, &#39;Jul&#39;, &#39;Oct&#39;)) +
  theme_bw()

g_m1</code></pre>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Before adding another function, we should consider the fact that the distribution we care most about modeling (number of monthly passengers) is not likely normally distributed. Currently the model makes the assumption that it is, which may have contributed to some of the initial warning messages the <code>Stan</code> model returned. Semi-related is that the mean and variance of the time-series are shifting dramatically over the period examined here.</p>
<p>There is more than one way to address the issues of changing scale/variance and non-normality. In this case, I am going to apply a simple log-transform on the airline passenger values. We can do this in the Stan code itself:</p>
<pre class="stan"><code>transformed data { 
    vector[N1] mu;
    vector[N1] y_log;
    for(n in 1:N1){
      mu[n] = 0;
      y_log[n] = log(Y[n]);
    } 
}</code></pre>
<p>With the transform added we can re-run our model with the single sqaured exponential covariance function.</p>
<pre class="r"><code># Model is the same in terms of parameters - just transformed the variable to log space
m2_pars.to.monitor &lt;- m1_pars.to.monitor

m2 &lt;- stan(
  file = &#39;../../blog_code/gp_m2.stan&#39;,
  data = m1_data, 
  warmup = 1000,
  iter = 2000,
  refresh=1000,
  chains = 6,
  pars = m2_pars.to.monitor,
  control = list(adapt_delta = .95, 
                 max_treedepth = 10), 
  seed = 20030414
)</code></pre>
<p>There are no warnings, which is always a welcome sign, and the model seems to converge without much issue. (I am moving quickly through these modeling steps. You would definitely want to perform more posterior checks than what I am doing here.)</p>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>And now for our model comparison: raw vs. log-transformed.</p>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Despite the greater degree of uncertainty, visual inspection of the plots leads me to think that the log-transformed approach is a little better. The lack of warning messages is also a plus. Neither of these models is particularly good, and that is why we are going to add another GP that accounts for seasonality in the time series. Hopefully that can give us some curvier forecasts.</p>
<p><span class="math display">\[k(t,t&#39;)=\sigma_2^2 exp\Big(-\frac{2sin^2(\pi(t-t&#39;)*1)}{l_2^2}\Big) exp\Big(-\frac{(t-t&#39;)^2}{2l_3^2}\Big)\]</span></p>
<p>Here is what that looks like when added to the <code>main_GP</code> function in our evolving Stan code. Note that you’ll also need to add the <code>rho</code> and <code>alpha</code> parameters in the appropriate locations. Raw code is available here.</p>
<pre class="stan"><code>for(i in 1:Nx){
    for(j in 1:Ny){
        K2[i, j] = alpha2*exp(-2*square(sin(pi()*fabs(x[i]-y[j])*1))/square(rho2))*
        exp(-square(x[i]-y[j])/2/square(rho3));
    }
}</code></pre>
<pre class="r"><code># Now more parameters to monitor
m3_pars.to.monitor &lt;- c(
  paste0(&#39;r&#39;, 1:3), 
  paste0(&#39;a&#39;, 1:2), 
  &#39;sigma_sq&#39;, 
  &#39;Ypred&#39;
)

m3 &lt;- stan(
  file = &#39;../../blog_code/gp_m3.stan&#39;,
  data = m1_data, 
  warmup = 1000,
  iter = 2000,
  refresh=1000,
  chains = 6,
  pars = m3_pars.to.monitor,
  control = list(adapt_delta = .95, 
                 max_treedepth = 10), 
  seed = 20030414
)</code></pre>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Well that is a huge improvement over the first few models. Adding in a term that addresses the obvious seasonal pattern improved model predictions immensely. My only gripe at this point is the fact that the “mean” posterior estimate tends to undershoot the observed data on average. It could just be the restricted range and the model would “over-predict” the next few months.</p>
<p>Returning to the initial list let us see what is still missing from the model</p>
<ol style="list-style-type: decimal">
<li>Over time there is an average increase in the number of passengers.</li>
</ol>
<p>The linear trend seems to be effectively captured by the first Gaussian process in the model - the squared exponential covariance kernel. An oversimplified description of that particular Gaussian process is that: <em>as the time between two points increases, the expected covariance in values decreases</em>.</p>
<ol style="list-style-type: decimal">
<li>There is a seasonal trend on top of the average increase that appears to be annual in nature, which would make sense for the airline industry in then (and probably now - COVID crisis notwithstanding).</li>
</ol>
<p>This was addressed in <code>m3</code> when we added a periodic kernel - notably one that has its own squared exponential covariance term attached to it. The concept here is that we are stating that there is some sort of seasonal trend and we can can model the periodicity as a function of the covariance matrix using the formula above <em>and</em> that periodic function may change over time. Essentially, the squared exponential covariance term added on the end of the periodic kernel makes it locally periodic.</p>
<ol style="list-style-type: decimal">
<li><p>The effect of the seasonal trends is more pronounced over time.
Addressed in two ways. The first is through the log-transform. The second is through the local nature of the periodic kernel.</p></li>
<li><p>There <em>may</em>, and I stress <em>may</em> be a slight acceleration in the, long-term increase in monthly passengers.
One way to think about this is that the decay in the association between two scores as a function of time is going to <em>accelerate</em>. At least that is my approach in <code>m4</code>. Below I add a third Gaussian process that enforces this concept. It is a squared exponential covariance kernel - our good old decay function - multiplied by a second squared exponential term. The idea here is that there is that the decay function is not constant. The further out we get in our forecasts, the less certain we should be about our predictions and observed data should be even less predictive of values in the increasingly distant future than the simple squared exponential kernel can account for on its own.</p></li>
</ol>
<pre class="r"><code># Easier to note these upfront
m4_pars.to.monitor &lt;- c(
  paste0(&#39;r&#39;, 1:5), 
  paste0(&#39;a&#39;, 1:3), 
  &#39;sigma_sq&#39;, 
  &#39;Ypred&#39;
)

#Note that I have a machine at home with 12 logical cores and 64GB of RAM
m4 &lt;- stan(
  file = &#39;../../blog_code/gp_m4.stan&#39;,
  data = m1_data, 
  warmup = 1000,
  iter = 2000,
  refresh=1000,
  chains = 6,
  pars = m4_pars.to.monitor,
  control = list(adapt_delta = .95, 
                 max_treedepth = 10), 
  seed = 20030414
)</code></pre>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Model 4 predictions extended from the observed data:</p>
<pre class="r"><code>g_m4.2 &lt;- 
brms::posterior_samples(m4, &#39;Ypred&#39;) %&gt;% 
  as.data.frame() %&gt;% 
  pivot_longer(cols = starts_with(&#39;Ypred&#39;), values_to = &#39;pass_log&#39;) %&gt;% 
  mutate(
    year = rep(air_pass_test[[&#39;year&#39;]], 6000), 
    pass = exp(pass_log)
  ) %&gt;%
  ggplot(aes(x = year, y = pass)) +
  stat_lineribbon(color = &quot;#08519C&quot;, fill = &#39;#426EBD&#39;, lwd = .5, .width = .95, alpha = .7) +
  geom_point(data = air_pass_train, aes(x = year, y = pass)) +
  geom_line(data = air_pass_train, aes(x = year, y = pass)) +
  labs(x = &quot;Year&quot;, y = &quot;Passengers (in thousands)&quot;, 
       caption = str_wrap(&#39;Model 4 - forecast: Three Gaussian process models combined&#39;)) +
  theme_bw()

g_m4.2</code></pre>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The predicted trend line has moved even closer to the observed, out-of-sample data with <code>m4</code>. Additionally, we see the expected behavior of our credibility interval. The farther out from the observed data we attempt to forecast, the more uncertain we are about the predictions. When thinking about models as engines that drive key decisions, being honest about how uncertain we are in forecasts is important, and too often overlooked.</p>
<p>At this point I am pretty satisfied with the Gaussian process model I have assembled here. As a point of comparison we can use an ARIMA model - a very common time-series model that can model seasonality and average trends over time as well. Hopefully, my approach will compare well against the more common technique.</p>
<p>Here is the model setup:</p>
<pre class="r"><code>(arima_fit&lt;- arima(log(AirPassengers[1:132]), c(0, 1, 1),
              seasonal = list(order = c(0, 1, 1), period = 12)))
update(arima_fit, method = &quot;CSS&quot;)

pred &lt;- predict(arima_fit, n.ahead = 12)
tl &lt;- pred$pred - 1.96 * pred$se
tu &lt;- pred$pred + 1.96 * pred$se

arima_forecast &lt;-data.frame(
  year=air_pass_test[[&#39;year&#39;]], 
  pass=exp(pred$pred), 
  UB=exp(as.numeric(tu)), 
  LB=exp(as.numeric(tl))
)</code></pre>
<p>And here are the results overlayed on top of the <code>m4</code> predictions and observed data.</p>
<p>Some key differences
1. The ARIMA takes a lot less time to execute. Gaussian process models are unfortunately <span class="math inline">\(O(N^3)\)</span> which means that as the number of data points increase the computation burden increases at an exponential rate.
1. The ARIMA model’s mean forecast is similar, but slightly worse than the Gaussian process model.
1. The ARIMA model is more certain about its predictions and while uncertainty does increase over time, the increase is not as pronounced.</p>
<p><img src="/blog/2018-05-21-gaussian-process-imputation-models_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Summary</p>

                        </div>
                        
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            
            <li>
                <a href="/categories/modeling">modeling (4)</a>
            </li>
            
        </ul>
    </div>

</div>








<div class="panel sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            
            <li>
                <a href="/tags/bayesian"><i class="fas fa-tags"></i> bayesian</a>
            </li>
            
            <li>
                <a href="/tags/data-visualization"><i class="fas fa-tags"></i> data-visualization</a>
            </li>
            
            <li>
                <a href="/tags/forecasting"><i class="fas fa-tags"></i> forecasting</a>
            </li>
            
            <li>
                <a href="/tags/gaussian-process"><i class="fas fa-tags"></i> gaussian-process</a>
            </li>
            
            <li>
                <a href="/tags/lavaan"><i class="fas fa-tags"></i> lavaan</a>
            </li>
            
            <li>
                <a href="/tags/missing-data"><i class="fas fa-tags"></i> missing-data</a>
            </li>
            
            <li>
                <a href="/tags/predictive-modeling"><i class="fas fa-tags"></i> predictive-modeling</a>
            </li>
            
            <li>
                <a href="/tags/r"><i class="fas fa-tags"></i> r</a>
            </li>
            
            <li>
                <a href="/tags/r-bloggers"><i class="fas fa-tags"></i> r-bloggers</a>
            </li>
            
            <li>
                <a href="/tags/simulation"><i class="fas fa-tags"></i> simulation</a>
            </li>
            
            <li>
                <a href="/tags/stan"><i class="fas fa-tags"></i> stan</a>
            </li>
            
        </ul>
    </div>

</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            <p>Consulting company specializing in the design of open source data processing and analytics pipelines.</p>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2019/01/19/2019-01-19-visualizing-variance-in-multilevel-models-using-the-riverplot-package/">
                          
                            <img src="/img/banners/riverplot.png" class="img-responsive" alt="Visualizing Variance in Multilevel Models Using the Riverplot Package">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2019/01/19/2019-01-19-visualizing-variance-in-multilevel-models-using-the-riverplot-package/">Visualizing Variance in Multilevel Models Using the Riverplot Package</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2018/07/11/2018-07-12-interaction-plots-with-continuous-moderators-in-r/">
                          
                            <img src="/img/banners/continuous-interaction.png" class="img-responsive" alt="Interaction Plots with Continuous Moderators in R">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2018/07/11/2018-07-12-interaction-plots-with-continuous-moderators-in-r/">Interaction Plots with Continuous Moderators in R</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2018/06/07/2018-06-07-power-analyses-for-an-unconditional-growth-model-using-lmer/">
                          
                            <img src="/img/banners/power-analysis-growth-model-banner.png" class="img-responsive" alt="Power Analyses for an Unconditional Growth Model using {lmer}">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2018/06/07/2018-06-07-power-analyses-for-an-unconditional-growth-model-using-lmer/">Power Analyses for an Unconditional Growth Model using {lmer}</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <p class="text-uppercase"><strong>Dead Reckoning Analytics & Consulting</strong>
        <br>PO Box 194
        <br>College Park, MD 20740
        <strong>United States</strong>
      </p>
      

            <a href="/contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2020, Dead Reckoning Analytics & Consulting, LLC; all rights reserved.</p>
            
            <p class="pull-right">
              Template by <a href="https://bootstrapious.com/p/universal-business-e-commerce-template">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>.
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-130198222-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?v=3.exp"></script>

<script src="/js/hpneo.gmaps.js"></script>
<script src="/js/gmaps.init.js"></script>
<script src="/js/front.js"></script>


<script src="/js/owl.carousel.min.js"></script>



  </body>
</html>
