<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.43" />
  <meta name="author" content="Matthew Barstead">

  
  
  
  
    
      
    
  
  <meta name="description" content="Spurred on by my boss Alex Shackman, I have been working to figure out a good way to visualize different sources of variation in momentary mood. The most common way of visually depicting variance decompositions from the sort of multilevel models we used to analyze our data is a stacked bar plot. So that seemed like a good place to start.
Figure 1 - Stacked Barplot of Model Variance Decomposition">

  
  <link rel="alternate" hreflang="en-us" href="/post/visualizing-variance-in-multilevel-models-using-the-riverplot-package/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-130198222-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/visualizing-variance-in-multilevel-models-using-the-riverplot-package/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@MGB_Research">
  <meta property="twitter:creator" content="@MGB_Research">
  
  <meta property="og:site_name" content="Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog">
  <meta property="og:url" content="/post/visualizing-variance-in-multilevel-models-using-the-riverplot-package/">
  <meta property="og:title" content="Visualizing Variance in Multilevel Models Using the Riverplot Package | Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog">
  <meta property="og:description" content="Spurred on by my boss Alex Shackman, I have been working to figure out a good way to visualize different sources of variation in momentary mood. The most common way of visually depicting variance decompositions from the sort of multilevel models we used to analyze our data is a stacked bar plot. So that seemed like a good place to start.
Figure 1 - Stacked Barplot of Model Variance Decomposition"><meta property="og:image" content="/img/River_header.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-01-19T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-01-19T00:00:00&#43;00:00">
  

  
  

  <title>Visualizing Variance in Multilevel Models Using the Riverplot Package | Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Matthew Barstead, Ph.D.: Research, Repository, &amp; Blog</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Blog</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/pdf/barstead_cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
            
          
        

        <li class="nav-item">
          <a href="https://www.r-bloggers.com/" target="_blank" rel="noopener">
            
            <span>R-Bloggers</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  
  
    <img src="/img/River_header.png" class="article-banner" itemprop="image">
  

  
</div>



  <div class="article-container">
    <h1 itemprop="name">Visualizing Variance in Multilevel Models Using the Riverplot Package</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2019-01-19 00:00:00 &#43;0000 UTC" itemprop="datePublished dateModified">
      Jan 19, 2019
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Matthew Barstead">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    21 min read
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/data-visualization/">Data Visualization</a
    >, 
    
    <a href="/categories/multilevel-modeling/">Multilevel Modeling</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Visualizing%20Variance%20in%20Multilevel%20Models%20Using%20the%20Riverplot%20Package&amp;url=%2fpost%2fvisualizing-variance-in-multilevel-models-using-the-riverplot-package%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fvisualizing-variance-in-multilevel-models-using-the-riverplot-package%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fvisualizing-variance-in-multilevel-models-using-the-riverplot-package%2f&amp;title=Visualizing%20Variance%20in%20Multilevel%20Models%20Using%20the%20Riverplot%20Package"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fvisualizing-variance-in-multilevel-models-using-the-riverplot-package%2f&amp;title=Visualizing%20Variance%20in%20Multilevel%20Models%20Using%20the%20Riverplot%20Package"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Visualizing%20Variance%20in%20Multilevel%20Models%20Using%20the%20Riverplot%20Package&amp;body=%2fpost%2fvisualizing-variance-in-multilevel-models-using-the-riverplot-package%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      <p>Spurred on by my boss <a href="https://psyc.umd.edu/facultyprofile/shackman/alexander">Alex Shackman</a>, I have been working to figure out a good way to visualize different sources of variation in momentary mood. The most common way of visually depicting variance decompositions from the sort of multilevel models we used to analyze our data is a stacked bar plot. So that seemed like a good place to start.</p>
<div class="figure">
<img src="/img/Variance_Graphic_Positive.png" alt="Figure 1 - Stacked Barplot of Model Variance Decomposition" />
<p class="caption"><em>Figure 1</em> - Stacked Barplot of Model Variance Decomposition</p>
</div>
<p>Now, choosing a color scheme that screams “HI I’M A COLOR!!” is one reasonable critique of this image. But, my more pressing issue is that this image, while accurately representing our model results asks a lot of the reader. You have to move back and forth between the legend and the graph to effectively map the different sources of explained variance onto their segments in the bar plot. Additioanlly, the denominator for the variance calculations shifts as you move across the <em>x</em> axis, and it may not be obvious to readers with passing familiarity of these models how the stacked bar plots in the right 2 columns merge together to form the stacked bar plot in the “Total” variance column. Relatedly, there is no place in this image to easily represent the total variance accounted for by between-subjects factors and within-subjects factors separately.</p>
<p>Unsatisfied with this graph, I played around with a number of different visualization approaches. Here is another attempt in which I tried to use the posterior distribution from our mood models, separate color schemes for between- and within-subjects sources of variation, and pie charts to provide a different visual breakdown of the variance terms. Within the violin plot on the left, I think I was going for something like the fundraising thermometer image churches place on roadsides to indicate how close they are to getting that new roof or expanding their parking lots.</p>
<div class="figure">
<img src="/img/Test_comb_vardecomp.png" alt="Figure 2 - Combined Posterior Distribution Thermometer Plot and Pie Charts" />
<p class="caption"><em>Figure 2</em> - Combined Posterior Distribution Thermometer Plot and Pie Charts</p>
</div>
<p>I liked the idea of including the posterior distibution from the models in this way so the reader could see that our model results mirrored the obtained data and our general expectation that negative mood is positively skewed in a relatively healthy population like the one we sampled. However, I did not like the execution of this vision, which yielded a busy plot that still requires a lot of work on the part of the reader to decipher the meaning of its components.</p>
<p>I knew there had to be a more elegant way to visually relate our findings to a reader. Data visualization after all should easliy summarize findings in a straightforward, transparent, and easy to digest way. These images are perhaps transparent in their representation of model results, but the are not straightforward and they are not easy to digest.</p>
<div id="enter-the-sankey-plot" class="section level1">
<h1>Enter the Sankey Plot</h1>
<p>So I did what all good researchers and data scientists do when they hit a wall, I searched the Internet for solutions. Here are just a couple of links I found helpful in my digital quest: <a href="http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html">Top 50 ggplot2 Visualizations</a> and <a href="https://www.r-graph-gallery.com/">The R Graph Gallery</a>. It was on this latter site that I came across the <a href="https://www.r-graph-gallery.com/sankey-diagram/">Sankey Diagram</a>. I immediately saw the potential to separate out between- and within-subjects variance, but also show how they combine to form the total variability in our dependent measure.</p>
<div class="figure">
<img src="/img/S1_PosMood_river.png" alt="Figure 3 - Our Final Riverplot - Based on Multiple Models" />
<p class="caption"><em>Figure 3</em> - Our Final Riverplot - Based on Multiple Models</p>
</div>
<p>This image ticks all of my data visaulization boxes, and, in my opinion, does a better job of representing what it is multilevel models do in terms of partitioning variance from multiple levels of the data. The remainder of this post is dedicated to how I got to this final plot. I will be including code from our models and I need to strongly recommend data scientists and researchers read <span class="citation">(Rights and Sterba 2018)</span>. For related discussions and adapting the approach for non-Gaussian distributed outcomes see <span class="citation">(Jaeger et al. 2017; Nakagawa and Schielzeth 2016)</span>. The <code>r2mlm</code> function Rights and Sterba <a href="https://my.vanderbilt.edu/jasonrights/software/r2mlm/">created</a> as part of their variance decomposition framework was instrumental in terms of my ability to extract the relevant variance components from our different models.</p>
<p>(<em>As an aside, Jason Rights was quick to respond to an email request of mine and re-uploaded his function after I had informed him that the original formatting on his site made it difficult to easily copy and paste into R. Thanks Jason!</em>)</p>
<p>The remainder of this post is going to be a walkthrough, with code snippets, of how I used the <code>r2mlm</code> function to extract variance components from our models and eventually create a plot the ticked all my nerdy data visualization boxes. This work is all part of a manuscript that will be sumbitted soon for publication, but I want to be upfront and say that the final products of that manuscript may not reflect exactly what you read here in this blog post.</p>
<p>I am going to provide a little background on our models and hypotheses, but it will not be exhaustive. I hope it is enough context to effectively understand how one might adapt this approach to their own multilevel data problems.</p>
</div>
<div id="methods-and-background" class="section level1">
<h1>Methods and Background</h1>
<p>There are numerous good resources out there that explain the basics of multilevel modeling <span class="citation">(Gelman et al. 2013; Gelman and Hill 2007; Raudenbush and Bryk 2002)</span>, and the goal of this post is not to recapitulate what is often a semester-long graduate course in the use of these models. Briefly, these models separate out sources of variability in nested data structures. The nesting can be individuals within groups (i.e., students within classrooms) or observations within individuals (i.e., repeated sampling of the same subjects).</p>
<p>Dr. Shackman’s data fall into this latter category. He and his collaborators designed a study in which college students responded to 10 survey prompts throughout the day, for an entire week (yielding up to 70 observations per participant). Along with basic questions about recent activities and social surroundings, participants provided information about how they felt at the moment they were responding to the survey (i.e., measures of negative and positive mood). They also rated how pleasant the “Best” event was that happened to them since the last prompt and how distressing the “Worst” event was that had occurred since their last survey.</p>
<p>A key construct in Dr. Shackman’s work is dispositional negativity - which is a risk factor for a host of undesirable and interconnected outcomes <span class="citation">(Shackman, Stockbridge, et al. 2016, 2018; Shackman, Tromp, et al. 2016; Shackman, Weinstein, et al. 2018)</span>. Where I come in is attempting to use his data to illustrate how it is dispositional negativity contributes to momentary mood and reactions to recent negative and positive events. I took the data from his 127 participants and, using <span class="citation">Bolger and Schilling (1991)</span> as a guide, set about the task of testing the different processes that link dispositional negativity to momentary affect.</p>
<p>One component of this research was separating out the unique variance explained by dispositional negativity from its shared variance with overall exposure to less positive and more negative daily events. To understand how this worked from a modeling standpoint, see the equations and walkthrough below. For simplicity’s sake I will be focusing solely on the positive mood model.</p>
</div>
<div id="decomposing-variance-from-single-model" class="section level1">
<h1>Decomposing Variance from Single Model</h1>
<p>The key innovation provided by Rights and Sterba (2018) with their integrated variance decomposition framework is the ability to extract <span class="math inline">\(R^2\)</span> values from multiple levels of a single multilevel model. Prior to the publication of this new technique, parsing sources of explained variance in a multilevel model was a non-trivial challenge that required multiple separate models and could occaisionally yield unsatisfactory results, including negative <span class="math inline">\(R^2\)</span> values (Gelman &amp; Hill, 2007; Rights &amp; Sterba, 2018).</p>
<p>We adapted the Rights and Sterba approach to our data and hypotheses and utilized their <code>r2MLM</code> function to partition between- and within-subjects sources of variation in our momentary mood variables. Because we hoped to isolate the total, unique, and shared (with exposure) variation in momentary mood accounted for by our primary predictor dispositional negativity, we did have to run several models in which we varied which level-2 predictors. The level-1 equation for each of these models remained constant and level-1 predictors were group-mean centered as a means of maintaining the separation of between- and within-subjects sources of variability in the model.</p>
<div id="level-1-equation" class="section level2">
<h2>Level 1 Equation:</h2>
<p><span class="math display">\[
\begin{aligned}
Y_{ti} = \pi_{0i} + \pi_{1i}(NegEvent_{ti} - \bar{NegEvent_{.i}}) + \pi_{2i}(PosEvent_{ti} - \bar{PosEvent_{.i}}) + e_{ti} 
\end{aligned}
\]</span></p>
<p>Our models diverged in their inclusion of predictors at the second level of the model. Model 1, which we used to examine the overall effect of dispositional negativity on momentary mood, included standardized dispositional negativity scores as the sole level-2 predictor.</p>
</div>
<div id="model-1-level-2-equations" class="section level2">
<h2>Model 1 Level-2 Equations:</h2>
<p><span class="math display">\[
\begin{aligned}
    \pi_{0i} = \beta_{00} + \beta_{01}(DN_i) + r_{0i} \\
    \pi_{1i} = \beta_{10} + r_{1i} \\
    \pi_{2i} = \beta_{20} + r_{2i}
\end{aligned}
\]</span>
In <code>R</code> the model was estimated using <code>brms</code>, a wraparound package developed for Bayesian regression models that draws on <a href="https://mc-stan.org/">Stan</a> a general purpose Bayesian modeling program <span class="citation">(Bürkner 2017)</span>.</p>
<pre class="r"><code>Pos_lv2_DN&lt;-brms::brm_multiple(T.PosAff~1+c.Worst+c.Best+
                                 c.DN+
                                 (1+c.Worst+c.Best|ID), 
                               data = dat.study1.list, 
                               family = &#39;normal&#39;,
                               prior = c(set_prior(&#39;student_t(3,0,1)&#39;, class=&#39;sd&#39;), 
                                         set_prior(&#39;normal(3.104,2)&#39;, class=&#39;Intercept&#39;), 
                                         set_prior(&#39;normal(0,5)&#39;, class=&#39;b&#39;), 
                                         set_prior(&#39;lkj(2)&#39;, class=&#39;cor&#39;)),
                               warmup = 2000, 
                               iter = 3000, 
                               chains = 3,
                               control = list(adapt_delta=.99, 
                                              max_treedepth=15), 
                               save_model = paste0(stan.code, &#39;/S1_lv2a.stan&#39;))</code></pre>
<p>The <code>brm_multiple</code> function integrates the results from the 20 imputed data sets we created to address missing survey responses in the data. If you do not have missing data, or you want to use a frequentist approach you will have to modify this walkthrough a little, and it will be more difficult to generate 95% Highest density intervals for variance estimates (which I can do by repeatedly drawing parameter estimates from the posterior distributions and re-calculating my <span class="math inline">\(R^2\)</span> terms).</p>
<p>To separately evaluate the overall effect of exposure (i.e., the tendency to report more negative and/or more positive events), Model 2 included individual averages of reported negative and positive events. These are sometimes referred to in the literature as contextual effects.</p>
</div>
<div id="model-2-level-2-equations" class="section level2">
<h2>Model 2 Level-2 Equations:</h2>
<p><span class="math display">\[
\begin{aligned}
  \pi_{0i} = \beta_{00} + \beta_{01}(\bar{NegEvent_{.i}}) + \beta_{02}(\bar{PosEvent_{.i}}) + r_{0i} \\
  \pi_{1i} = \beta_{10} + r_{1i} \\
  \pi_{2i} = \beta_{20} + r_{2i}
\end{aligned}
\]</span></p>
<p>In <code>R</code>…</p>
<pre class="r"><code>Pos_lv2_Evnt&lt;-brms::brm_multiple(T.PosAff~1+c.Worst+c.Best+
                                   mean.Worst+mean.Best+
                                   (1+c.Worst+c.Best|ID), 
                                 data = dat.study1.list, 
                                 family = &#39;normal&#39;,
                                 prior = c(set_prior(&#39;student_t(3,0,1)&#39;, class=&#39;sd&#39;), 
                                           set_prior(&#39;normal(3.104,2)&#39;, class=&#39;Intercept&#39;), 
                                           set_prior(&#39;normal(0,5)&#39;, class=&#39;b&#39;), 
                                           set_prior(&#39;lkj(2)&#39;, class=&#39;cor&#39;)),
                                 warmup = 2000, 
                                 iter = 3000, 
                                 chains = 3,
                                 control = list(adapt_delta=.99, 
                                                max_treedepth=15), 
                                 save_model = paste0(stan.code, &#39;/S1_lv2b.stan&#39;))</code></pre>
<p>Finally, we included all three individual-level predictors in Model 3. Doing so allowed us to separately calculate the unique and shared variability in momentary mood attributable to dispositional negativity and overall exposure to positive and negative daily events:</p>
</div>
<div id="model-3-level-2-equations" class="section level2">
<h2>Model 3 Level-2 Equations:</h2>
<p><span class="math display">\[
\begin{aligned}
  \pi_{0i} = \beta_{00} + \beta_{01}(DN_i) + \beta_{02}(\bar{NegEvent_{.i}}) + \beta_{03}(\bar{PosEvent_{.i}}) + r_{0i} \\
  \pi_{1i} = \beta_{10} + r_{1i} \\
  \pi_{2i} = \beta_{20} + r_{2i}
\end{aligned}
\]</span></p>
<p>In <code>R</code>…</p>
<pre class="r"><code>Pos_lv2_All&lt;-brms::brm_multiple(T.PosAff~1+c.Worst+c.Best+
                                  mean.Worst+mean.Best+c.DN+
                                  (1+c.Worst+c.Best|ID), 
                                data = dat.study1.list, 
                                family = &#39;normal&#39;,
                                prior = c(set_prior(&#39;student_t(3,0,1)&#39;, class=&#39;sd&#39;), 
                                          set_prior(&#39;normal(3.104,2)&#39;, class=&#39;Intercept&#39;), 
                                          set_prior(&#39;normal(0,5)&#39;, class=&#39;b&#39;), 
                                          set_prior(&#39;lkj(2)&#39;, class=&#39;cor&#39;)),
                                warmup = 2000, 
                                iter = 3000, 
                                chains = 3,
                                control = list(adapt_delta=.99, 
                                               max_treedepth=15), 
                                save_model = paste0(stan.code, &#39;/S1_lv2c.stan&#39;))</code></pre>
<p>Differences in between-subjects and total variance in momentary mood explained by each of these models formed the basis of our overall variance attributable to DN (<span class="math inline">\(R_{M1}^2\)</span>), unique variance associated with DN (<span class="math inline">\(R_{M3}^2 - R_{M1}^2\)</span>), and variance shared between DN and exposure (<span class="math inline">\(R_{M3}^2 - [R_{M3}^2 - R_{M1}^2]\)</span>), where <span class="math inline">\(R^2s\)</span> could represent total variability or be isolated solely to between-subjects variability in momentary mood and <span class="math inline">\(M1\)</span>, <span class="math inline">\(M2\)</span>, and <span class="math inline">\(M3\)</span> represent terms extracted from Models 1, 2, and 3 respectively. To complete our understanding of sources of between subjects variability in our models, we also estimated the variance explained by an individual’s average exposure to positive and negative events (<span class="math inline">\(R_{M3}^2 - R_{M2}^2\)</span>).</p>
<p>As noted above a strength of this Bayesian modeling approach is that we were able to draw parameter estimates from the posterior distributions implied by our models and calculate 95% highest density intervals for our various <span class="math inline">\(R^2\)</span> terms of interest across the imputed data sets.</p>
</div>
</div>
<div id="extracting-relevant-variance-terms-using-r2mlm" class="section level1">
<h1>Extracting Relevant Variance Terms using <code>r2mlm</code></h1>
<p>My approach to using this function is a little bit complicated because of the multiple imputations and the need to isolate specific variance terms from each model. If you do not have missing data (email me immediately and tell me your secrets), not everything I am about to do is necessary. Also if you do not have a posterior distribution to draw from, you won’t need to get a vector of <span class="math inline">\(R^2s\)</span>. Just running the <code>r2mlm</code> function once for each model will be sufficient.</p>
<p>First, I need to collect information to pass along to the <code>r2mlm</code> function, including the columns in my data that correspond to my variables in the model.</p>
<pre class="r"><code>#Attempting Variance Partionining for DN alone
within_cov&lt;-c(21,23)                    #Columns with group-mean centered predictors
between_cov&lt;-c(6)                       #Columns with between-subject predictors
random_cov&lt;-c(21,23)                    #Level 1 predictors with random slopes</code></pre>
<p>Next I extract the posterior distributions for my parameters as follows.</p>
<pre class="r"><code>#Getting distributions of fixed effects
Intercept&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;b_Intercept&#39;) 
DN&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;b_c.DN&#39;) 
Worst&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;b_c.Worst&#39;) 
Best&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;b_c.Best&#39;) 

#Getting between-subjects variance terms for random effects
Int_var&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__Intercept&#39;)^2
Worst_var&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Worst&#39;)^2 
Best_var&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Best&#39;)^2</code></pre>
<p>I am going to need a covariance matrix for my random effects in each model. Luckily this is relatively straightforward as long as you can remember that <span class="math inline">\(Cov(x,y) = r_{xy} sd_x sd_y\)</span>.</p>
<pre class="r"><code>#Getting covariances of random effects (i.e., tau matrix)
cov_Int_Worst&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;cor_ID__Intercept__c.Worst&#39;)

cov_Int_Best&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;cor_ID__Intercept__c.Best&#39;) 

cov_Worst_Best&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_DN, pars = &#39;cor_ID__c.Worst__c.Best&#39;)</code></pre>
<p>Last but not least, I need the level-1 residuals (i.e., <span class="math inline">\(\sigma_e^2\)</span>)</p>
<pre class="r"><code>#Getting level 1 error variance
sigma&lt;-posterior_samples(Pos_lv2_DN, pars = &#39;sigma&#39;)</code></pre>
<p>Having the main components it is time for some cleanup so that I can begin extracting variance terms from my model.</p>
<pre class="r"><code>post_samples&lt;-data.frame(Intercept,
                         DN, 
                         Worst, 
                         Best, 
                         Int_var, 
                         Worst_var, 
                         Best_var, 
                         cov_Int_Worst, 
                         cov_Int_Best, 
                         cov_Worst_Best, 
                         sigma)

colnames(post_samples)&lt;-c(&#39;Intercept&#39;, 
                          &#39;DN&#39;, 
                          &#39;Worst&#39;, 
                          &#39;Best&#39;, 
                          &#39;Int_var&#39;, 
                          &#39;Worst_var&#39;, 
                          &#39;Best_var&#39;,
                          &#39;cov_Int_Worst&#39;, 
                          &#39;cov_Int_Best&#39;, 
                          &#39;cov_Worst_Best&#39;, 
                          &#39;sigma&#39;)</code></pre>
<p>I mentioned before that I am going to be taking a Bayesian approach here, which means sampling repeatedly from my posterior distributions. This approach is complicated slightly by the fact that my posterior distributions are unique to each of the 20 datasets I imputed. This means I need to be deliberate about how I sample from the posterior and which of the 20 data sets I apply the sampled parameter estimates to when running the <code>r2mlm</code> function. The code below makes this happen and extracts the variance terms of interest for my final graphic.</p>
<pre class="r"><code>#Aggregate across imputed datasets
#Currently going to take 1000 draws from posterior distributions
#Will then apply across all 20 data sets

P_DN_alone&lt;-list(between_var=vector(), 
               within_var=vector(), 
               between_All_tot=vector(),
               between_All_btw=vector(),
               between_res_btw=vector(),
               within_fix_wthn=vector(),
               within_fix_tot=vector(),
               within_slope_var_wthn=vector(),
               within_res_wthn=vector(), 
               within_unmod_tot=vector())

#Will be used to line up posterior distributions 
#Because  posterior parameter estimates are unique to each imputed data set
#Probably ways to make this more programmatically fluid... 
sampling_list&lt;-list(imp1 = 1:3000, 
                    imp2 = 1:3000 + 3000, 
                    imp3 = 1:3000 + 6000, 
                    imp4 = 1:3000 + 9000,
                    imp5 = 1:3000 + 12000,
                    imp6 = 1:3000 + 15000,
                    imp7 = 1:3000 + 18000,
                    imp8 = 1:3000 + 21000,
                    imp9 = 1:3000 + 24000,
                    imp10 = 1:3000 + 27000,
                    imp11 = 1:3000 + 30000,
                    imp12 = 1:3000 + 33000,
                    imp13 = 1:3000 + 36000,
                    imp14 = 1:3000 + 39000,
                    imp15 = 1:3000 + 42000,
                    imp16 = 1:3000 + 45000,
                    imp17 = 1:3000 + 48000,
                    imp18 = 1:3000 + 51000,
                    imp19 = 1:3000 + 54000,
                    imp20 = 1:3000 + 57000)

for(i in 1:length(dat.study1.list)){
  print(paste(&#39;Starting w/ imputed set&#39;, i, &#39;out of&#39;, M))
  D&lt;-sample(sampling_list[[i]], size = 1000, replace = FALSE)
  for(d in 1:length(D)){
    #browser()
    Gamma_w&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Worst&#39;, &#39;Best&#39;)]))       #Make sure the effects line up - in order of within_cov
    Gamma_b&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Intercept&#39;, &#39;DN&#39;)]))    #level fixed intercept and any level 2 fixed effects
    tau&lt;-c(post_samples[D[d], c(&#39;Int_var&#39;, &#39;cov_Int_Worst&#39;, &#39;cov_Int_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Worst&#39;, &#39;Worst_var&#39;, &#39;cov_Worst_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Best&#39;, &#39;cov_Worst_Best&#39;, &#39;Best_var&#39;)])
    
    tau&lt;-matrix(unlist(tau), 
                byrow=TRUE, 
                ncol=3)
    
    #Matrix rows/columns ordered starting with tau.00 (intercept variance)
    #then add columns/rows for random effects of slopes in order of within_cov
    
    Sigma2&lt;-post_samples[D[d], &#39;sigma&#39;]
    
    r2mlm_DN&lt;-r2MLM(data=dat.study1.list[[i]], 
                    within_covs = within_cov, 
                    between_covs = between_cov, 
                    random_covs = random_cov, 
                    gamma_w = Gamma_w, 
                    gamma_b = Gamma_b, 
                    Tau = tau, 
                    sigma2 = Sigma2, 
                    has_intercept = TRUE, 
                    clustermeancentered = TRUE)
    
    #Extracting relevant values across imputed datasets
    P_DN_alone$between_var&lt;-c(P_DN_alone$between_var, as.numeric(r2mlm_DN$Decompositions[&#39;fixed, between&#39;, &#39;total&#39;])+
                              as.numeric(r2mlm_DN$Decompositions[&#39;mean variation&#39;, &#39;total&#39;]))
    P_DN_alone$within_var&lt;-c(P_DN_alone$within_var, as.numeric(r2mlm_DN$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                             as.numeric(r2mlm_DN$Decompositions[&#39;slope variation&#39;, &#39;total&#39;])+
                             as.numeric(r2mlm_DN$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_DN_alone$between_All_tot&lt;-c(P_DN_alone$between_All_tot, as.numeric(r2mlm_DN$R2s[&#39;f2&#39;, &#39;total&#39;]))
    P_DN_alone$between_All_btw&lt;-c(P_DN_alone$between_All_btw, as.numeric(r2mlm_DN$R2s[&#39;f2&#39;, &#39;between&#39;]))
    P_DN_alone$between_res_btw&lt;-c(P_DN_alone$between_res_btw, as.numeric(r2mlm_DN$R2s[&#39;m&#39;, &#39;between&#39;]))
    P_DN_alone$within_fix_wthn&lt;-c(P_DN_alone$within_fix_wthn, as.numeric(r2mlm_DN$Decompositions[&#39;fixed, within&#39;, &#39;within&#39;]))
    P_DN_alone$within_fix_tot&lt;-c(P_DN_alone$within_fix_wthn, as.numeric(r2mlm_DN$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_DN_alone$within_slope_var_wthn&lt;-c(P_DN_alone$within_slope_var, as.numeric(r2mlm_DN$Decompositions[&#39;slope variation&#39;, &#39;within&#39;]))
    P_DN_alone$within_res_wthn&lt;-c(P_DN_alone$within_res_wthn, as.numeric(r2mlm_DN$Decompositions[&#39;sigma2&#39;, &#39;within&#39;]))
    P_DN_alone$within_unmod_tot&lt;-c(P_DN_alone$within_unmod_wthn, as.numeric(r2mlm_DN$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                                   as.numeric(r2mlm_DN$Decompositions[&#39;slope variation&#39;, &#39;total&#39;]))
    
    print(paste(&quot;Sampling&quot;, d, &quot;out of&quot;, length(D), &#39;- Dataset:&#39;, i))
  }
  print(paste(&quot;*** Finshed imputed data set&quot;, i, &#39;out of&#39;, M, &quot;***&quot;))
}</code></pre>
<p>I then repeat this approach with the average event ratings as the sole predictors of the intercept.</p>
<pre class="r"><code>#Event only model (these are context effects on intercept)
within_cov&lt;-c(21,23)                    #Columns with group-mean centered predictors
between_cov&lt;-c(22, 24)                  #Columns with between-subject predictors
random_cov&lt;-c(21,23)                    #Level 1 predictors with random slopes

#Getting distributions of fixed effects
Intercept&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;b_Intercept&#39;) 
M.Worst&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;b_mean.Worst&#39;)
M.Best&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;b_mean.Best&#39;)
Worst&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;b_c.Worst&#39;) 
Best&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;b_c.Best&#39;) 

#Getting between-subjects variance terms for random effects
Int_var&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__Intercept&#39;)^2
Worst_var&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Worst&#39;)^2 
Best_var&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Best&#39;)^2

#Getting covariances of random effects (i.e., tau matrix)
cov_Int_Worst&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;cor_ID__Intercept__c.Worst&#39;)

cov_Int_Best&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;cor_ID__Intercept__c.Best&#39;) 

cov_Worst_Best&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_Evnt, pars = &#39;cor_ID__c.Worst__c.Best&#39;)

#Getting level 1 error variance
sigma&lt;-posterior_samples(Pos_lv2_Evnt, pars = &#39;sigma&#39;)
post_samples&lt;-data.frame(Intercept,
                         M.Worst,
                         M.Best,
                         Worst, 
                         Best, 
                         Int_var, 
                         Worst_var, 
                         Best_var, 
                         cov_Int_Worst, 
                         cov_Int_Best, 
                         cov_Worst_Best, 
                         sigma)

colnames(post_samples)&lt;-c(&#39;Intercept&#39;, 
                          &#39;M.Worst&#39;,
                          &#39;M.Best&#39;,
                          &#39;Worst&#39;, 
                          &#39;Best&#39;, 
                          &#39;Int_var&#39;, 
                          &#39;Worst_var&#39;, 
                          &#39;Best_var&#39;,
                          &#39;cov_Int_Worst&#39;, 
                          &#39;cov_Int_Best&#39;, 
                          &#39;cov_Worst_Best&#39;, 
                          &#39;sigma&#39;)
#Aggregate across imputed datasets
#Currently going to take 1000 draws from posterior distributions
#Will then apply across all 20 data sets
P_Evnt_alone&lt;-list(between_var=vector(), 
                 within_var=vector(), 
                 between_All_tot=vector(),
                 between_All_btw=vector(),
                 between_res_btw=vector(),
                 within_fix_wthn=vector(),
                 within_fix_tot=vector(),
                 within_slope_var_wthn=vector(),
                 within_res_wthn=vector(), 
                 within_unmod_tot=vector())

for(i in 1:length(dat.study1.list)){
  print(paste(&#39;Starting w/ imputed set&#39;, i, &#39;out of&#39;, M))
  D&lt;-sample(sampling_list[[i]], size = 1000, replace = FALSE)
  for(d in 1:length(D)){
    #browser()
    Gamma_w&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Worst&#39;, &#39;Best&#39;)]))       #Make sure the effects line up - in order of within_cov
    Gamma_b&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Intercept&#39;, &#39;M.Worst&#39;, &#39;M.Best&#39;)]))    #level fixed intercept and any level 2 fixed effects
    tau&lt;-c(post_samples[D[d], c(&#39;Int_var&#39;, &#39;cov_Int_Worst&#39;, &#39;cov_Int_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Worst&#39;, &#39;Worst_var&#39;, &#39;cov_Worst_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Best&#39;, &#39;cov_Worst_Best&#39;, &#39;Best_var&#39;)])
    
    tau&lt;-matrix(unlist(tau), 
                byrow=TRUE, 
                ncol=3)
    
    #Matrix rows/columns ordered starting with tau.00 (intercept variance)
    #then add columns/rows for random effects of slopes in order of within_cov
    
    Sigma2&lt;-post_samples[D[d], &#39;sigma&#39;]
    
    r2mlm_Evnt&lt;-r2MLM(data=dat.study1.list[[i]], 
                      within_covs = within_cov, 
                      between_covs = between_cov, 
                      random_covs = random_cov, 
                      gamma_w = Gamma_w, 
                      gamma_b = Gamma_b, 
                      Tau = tau, 
                      sigma2 = Sigma2, 
                      has_intercept = TRUE, 
                      clustermeancentered = TRUE)
    
    #Extracting relevant values across imputed datasets
    P_Evnt_alone$between_var&lt;-c(P_Evnt_alone$between_var, as.numeric(r2mlm_Evnt$Decompositions[&#39;fixed, between&#39;, &#39;total&#39;])+
                                as.numeric(r2mlm_Evnt$Decompositions[&#39;mean variation&#39;, &#39;total&#39;]))
    P_Evnt_alone$within_var&lt;-c(P_Evnt_alone$within_var, as.numeric(r2mlm_Evnt$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                               as.numeric(r2mlm_Evnt$Decompositions[&#39;slope variation&#39;, &#39;total&#39;])+
                               as.numeric(r2mlm_Evnt$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_Evnt_alone$between_All_tot&lt;-c(P_Evnt_alone$between_All_tot, as.numeric(r2mlm_Evnt$R2s[&#39;f2&#39;, &#39;total&#39;]))
    P_Evnt_alone$between_All_btw&lt;-c(P_Evnt_alone$between_All_btw, as.numeric(r2mlm_Evnt$R2s[&#39;f2&#39;, &#39;between&#39;]))
    P_Evnt_alone$between_res_btw&lt;-c(P_Evnt_alone$between_res_btw, as.numeric(r2mlm_Evnt$R2s[&#39;m&#39;, &#39;between&#39;]))
    P_Evnt_alone$within_fix_wthn&lt;-c(P_Evnt_alone$within_fix_wthn, as.numeric(r2mlm_Evnt$Decompositions[&#39;fixed, within&#39;, &#39;within&#39;]))
    P_Evnt_alone$within_fix_tot&lt;-c(P_Evnt_alone$within_fix_wthn, as.numeric(r2mlm_Evnt$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_Evnt_alone$within_slope_var_wthn&lt;-c(P_Evnt_alone$within_slope_var, as.numeric(r2mlm_Evnt$Decompositions[&#39;slope variation&#39;, &#39;within&#39;]))
    P_Evnt_alone$within_res_wthn&lt;-c(P_Evnt_alone$within_res_wthn, as.numeric(r2mlm_Evnt$Decompositions[&#39;sigma2&#39;, &#39;within&#39;]))
    P_Evnt_alone$within_unmod_tot&lt;-c(P_Evnt_alone$within_unmod_wthn, as.numeric(r2mlm_Evnt$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                                     as.numeric(r2mlm_Evnt$Decompositions[&#39;slope variation&#39;, &#39;total&#39;]))
    
    print(paste(&quot;Sampling&quot;, d, &quot;out of&quot;, length(D), &#39;- Dataset:&#39;, i))
  }
  print(paste(&quot;*** Finshed imputed data set&quot;, i, &#39;out of&#39;, M, &quot;***&quot;))
}</code></pre>
<p>And finally, I do the same with the combined model.</p>
<pre class="r"><code>#Combined Level 2 Model (these are context effects on intercept)
within_cov&lt;-c(21,23)                    #Columns with group-mean centered predictors
between_cov&lt;-c(6, 22, 24)               #Columns with between-subject predictors
random_cov&lt;-c(21,23)                    #Level 1 predictors with random slopes

#Getting distributions of fixed effects
Intercept&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_Intercept&#39;) 
DN&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_c.DN&#39;)
M.Worst&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_mean.Worst&#39;)
M.Best&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_mean.Best&#39;)
Worst&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_c.Worst&#39;) 
Best&lt;-posterior_samples(Pos_lv2_All, pars = &#39;b_c.Best&#39;) 

#Getting between-subjects variance terms for random effects
Int_var&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__Intercept&#39;)^2
Worst_var&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Worst&#39;)^2 
Best_var&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Best&#39;)^2

#Getting covariances of random effects (i.e., tau matrix)
cov_Int_Worst&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;cor_ID__Intercept__c.Worst&#39;)

cov_Int_Best&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__Intercept&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;cor_ID__Intercept__c.Best&#39;) 

cov_Worst_Best&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Worst&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;sd_ID__c.Best&#39;)*
  posterior_samples(Pos_lv2_All, pars = &#39;cor_ID__c.Worst__c.Best&#39;)

#Getting level 1 error variance
sigma&lt;-posterior_samples(Pos_lv2_All, pars = &#39;sigma&#39;)
post_samples&lt;-data.frame(Intercept,
                         DN,
                         M.Worst,
                         M.Best,
                         Worst, 
                         Best, 
                         Int_var, 
                         Worst_var, 
                         Best_var, 
                         cov_Int_Worst, 
                         cov_Int_Best, 
                         cov_Worst_Best, 
                         sigma)

colnames(post_samples)&lt;-c(&#39;Intercept&#39;, 
                          &#39;DN&#39;,
                          &#39;M.Worst&#39;,
                          &#39;M.Best&#39;,
                          &#39;Worst&#39;, 
                          &#39;Best&#39;, 
                          &#39;Int_var&#39;, 
                          &#39;Worst_var&#39;, 
                          &#39;Best_var&#39;,
                          &#39;cov_Int_Worst&#39;, 
                          &#39;cov_Int_Best&#39;, 
                          &#39;cov_Worst_Best&#39;, 
                          &#39;sigma&#39;)
#Aggregate across imputed datasets
#Currently going to take 1000 draws from posterior distributions
#Will then apply across all 20 data sets
P_Lv2_comb&lt;-list(between_var=vector(), 
               within_var=vector(), 
               between_All_tot=vector(),
               between_All_btw=vector(),
               between_res_btw=vector(),
               within_fix_wthn=vector(),
               within_fix_tot=vector(),
               within_slope_var_wthn=vector(),
               within_res_wthn=vector(), 
               within_unmod_tot=vector())

for(i in 1:length(dat.study1.list)){
  print(paste(&#39;Starting w/ imputed set&#39;, i, &#39;out of&#39;, M))
  D&lt;-sample(sampling_list[[i]], size = 1000, replace = FALSE)
  for(d in 1:length(D)){
    #browser()
    Gamma_w&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Worst&#39;, &#39;Best&#39;)]))       #Make sure the effects line up - in order of within_cov
    Gamma_b&lt;-as.vector(
      as.matrix(
        post_samples[D[d], c(&#39;Intercept&#39;, &#39;DN&#39;, &#39;M.Worst&#39;, &#39;M.Best&#39;)]))    #level fixed intercept and any level 2 fixed effects
    tau&lt;-c(post_samples[D[d], c(&#39;Int_var&#39;, &#39;cov_Int_Worst&#39;, &#39;cov_Int_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Worst&#39;, &#39;Worst_var&#39;, &#39;cov_Worst_Best&#39;)], 
           post_samples[D[d], c(&#39;cov_Int_Best&#39;, &#39;cov_Worst_Best&#39;, &#39;Best_var&#39;)])
    
    tau&lt;-matrix(unlist(tau), 
                byrow=TRUE, 
                ncol=3)
    
    #Matrix rows/columns ordered starting with tau.00 (intercept variance)
    #then add columns/rows for random effects of slopes in order of within_cov
    
    Sigma2&lt;-post_samples[D[d], &#39;sigma&#39;]
    
    r2mlm_All&lt;-r2MLM(data=dat.study1.list[[i]], 
                     within_covs = within_cov, 
                     between_covs = between_cov, 
                     random_covs = random_cov, 
                     gamma_w = Gamma_w, 
                     gamma_b = Gamma_b, 
                     Tau = tau, 
                     sigma2 = Sigma2, 
                     has_intercept = TRUE, 
                     clustermeancentered = TRUE)
    
    #Extracting relevant values across imputed datasets
    P_Lv2_comb$between_var&lt;-c(P_Lv2_comb$between_var, as.numeric(r2mlm_All$Decompositions[&#39;fixed, between&#39;, &#39;total&#39;])+
                              as.numeric(r2mlm_All$Decompositions[&#39;mean variation&#39;, &#39;total&#39;]))
    P_Lv2_comb$within_var&lt;-c(P_Lv2_comb$within_var, as.numeric(r2mlm_All$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                             as.numeric(r2mlm_All$Decompositions[&#39;slope variation&#39;, &#39;total&#39;])+
                             as.numeric(r2mlm_All$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_Lv2_comb$between_All_tot&lt;-c(P_Lv2_comb$between_All_tot, as.numeric(r2mlm_All$R2s[&#39;f2&#39;, &#39;total&#39;]))
    P_Lv2_comb$between_All_btw&lt;-c(P_Lv2_comb$between_All_btw, as.numeric(r2mlm_All$R2s[&#39;f2&#39;, &#39;between&#39;]))
    P_Lv2_comb$between_res_btw&lt;-c(P_Lv2_comb$between_res_btw, as.numeric(r2mlm_All$R2s[&#39;m&#39;, &#39;between&#39;]))
    P_Lv2_comb$within_fix_wthn&lt;-c(P_Lv2_comb$within_fix_wthn, as.numeric(r2mlm_All$Decompositions[&#39;fixed, within&#39;, &#39;within&#39;]))
    P_Lv2_comb$within_fix_tot&lt;-c(P_Lv2_comb$within_fix_wthn, as.numeric(r2mlm_All$Decompositions[&#39;fixed, within&#39;, &#39;total&#39;]))
    P_Lv2_comb$within_slope_var_wthn&lt;-c(P_Lv2_comb$within_slope_var, as.numeric(r2mlm_All$Decompositions[&#39;slope variation&#39;, &#39;within&#39;]))
    P_Lv2_comb$within_res_wthn&lt;-c(P_Lv2_comb$within_res_wthn, as.numeric(r2mlm_All$Decompositions[&#39;sigma2&#39;, &#39;within&#39;]))
    P_Lv2_comb$within_unmod_tot&lt;-c(P_Lv2_comb$within_unmod_wthn, as.numeric(r2mlm_All$Decompositions[&#39;sigma2&#39;, &#39;total&#39;])+
                                   as.numeric(r2mlm_All$Decompositions[&#39;slope variation&#39;, &#39;total&#39;]))
    
    print(paste(&quot;Sampling&quot;, d, &quot;out of&quot;, length(D), &#39;- Dataset:&#39;, i))
  }
  print(paste(&quot;*** Finshed imputed data set&quot;, i, &#39;out of&#39;, M, &quot;***&quot;))
}</code></pre>
<p>Now that I have all of the values I need for my plot, I am just a few calculations away from getting what I want. As a quick aside here, note that I can now get 95% highest density intervals for my different variance terms using different adaptations of the following code: <code>quantile(P_DN_alone$between_All_tot, c(.025, .975))</code>.</p>
</div>
<div id="using-the-riverplot-package" class="section level1">
<h1>Using the <code>riverplot</code> Package</h1>
<p>Remember this all started with a desire to get a graphic that was straightforward, transparent, and easy to digest?</p>
<p>Well we are almost there, but first, I need to isolate the variance explained by the dispositional negativity variable (<code>DN</code>) and the shared variance between <code>DN</code> and individual variation in the average ratings of positive and negative daily events. I also threw in the unique variance explained by average exposure to positive and negative events, above and beyond individual differences in dispositional negativity.</p>
<pre class="r"><code>P_btw_DN_uni_tot&lt;-mean(P_Lv2_comb$between_All_tot)-mean(P_Evnt_alone$between_All_tot)
P_btw_shared_tot&lt;-mean(P_DN_alone$between_All_tot)-P_btw_DN_uni_tot
P_btw_context_uni_tot&lt;-mean(P_Lv2_comb$between_All_tot)-mean(P_DN_alone$between_All_tot)

sum(c(P_btw_DN_uni_tot, 
      P_btw_shared_tot,
      P_btw_context_uni_tot))

#The above total should equal: 
mean(P_Lv2_comb$between_All_tot)

#Now getting the between subjects residual variance from final model
P_btw_res_tot&lt;-mean(P_Lv2_comb$between_var-P_Lv2_comb$between_All_tot)
P_btw_res_tot+sum(c(P_btw_DN_uni_tot, 
                    P_btw_shared_tot,
                    P_btw_context_uni_tot))</code></pre>
<p>Now it is the within-subject variance I need to extract:</p>
<pre class="r"><code>#Final getting the within subjects variance: 
P_wthn_best_worst_tot&lt;-mean(P_Lv2_comb$within_fix_tot)
P_wthn_res_tot&lt;-mean(P_Lv2_comb$within_var)-P_wthn_best_worst_tot

#Should be equal to 1
sum(c(P_wthn_best_worst_tot, 
      P_wthn_res_tot, 
      mean(P_Lv2_comb$between_var)))</code></pre>
<p>And finally the total between- and within-subjects variability estimated in the models.</p>
<pre class="r"><code>P_tot_btw&lt;-mean(P_Lv2_comb$between_var)
P_tot_wthn&lt;-mean(P_Lv2_comb$within_var)  </code></pre>
<p>Using the <code>riverplot</code> package <span class="citation">(Weiner 2017)</span>, I then created my Sankey diagram as follows:</p>
<pre class="r"><code>River_DF&lt;-data.frame(N1 = c(&#39;DN&#39;,
                            &#39;DN &lt;--&gt; Exposure&#39;,
                            &#39;Exposure&#39;, 
                            &#39;Unmodeled Between&#39;, 
                            &#39;Momentary Events&#39;, 
                            &#39;Unmodeled Within&#39;, 
                            &#39;Total Between&#39;, 
                            &#39;Total Within&#39;), 
                     N2 = c(&#39;Total Between&#39;, 
                            &#39;Total Between&#39;, 
                            &#39;Total Between&#39;, 
                            &#39;Total Between&#39;, 
                            &#39;Total Within&#39;, 
                            &#39;Total Within&#39;, 
                            &#39;Total Variance&#39;, 
                            &#39;Total Variance&#39;), 
                     Value = c(P_btw_DN_uni_tot, 
                               P_btw_shared_tot,
                               P_btw_context_uni_tot, 
                               P_btw_res_tot, 
                               P_wthn_best_worst_tot, 
                               P_wthn_res_tot, 
                               P_tot_btw, 
                               P_tot_wthn), 
                     ID = 1:8)

River_DF$N1&lt;-paste(River_DF$N1, 
                   &#39;\n&#39;, 
                   paste0(round(River_DF$Value*100, 
                                digits = 2), &#39;%&#39;
                   )
)
River_DF$N2&lt;-c(rep(River_DF$N1[7], 4),
               rep(River_DF$N1[8], 2), 
               rep(&#39;Total Variance&#39;, 2)
)

nodes&lt;-data.frame(ID = c(River_DF$N1, 
                         &#39;Total Variance&#39;), 
                  x = c(1,1,1,1,1,1,2,2,3), 
                  y = c(0,1.5,3.25,5.25,8,10.5,2.5,7.5,5))

palette = c(paste0(brewer.pal(9, &quot;Blues&quot;), 90)[c(2, 4, 6, 8)], 
            paste0(brewer.pal(9, &quot;Reds&quot;), 90)[c(6, 8)], 
            paste0(brewer.pal(9, &quot;Blues&quot;), 90)[9], 
            paste0(brewer.pal(9, &quot;Reds&quot;), 90)[9], 
            paste0(brewer.pal(9, &#39;Purples&#39;), 90)[9])

styles = lapply(nodes$y, function(n) {
  list(col = palette[n], lty = 0, textcol = &quot;black&quot;)
})

#Not sure why color is not mapping correctly with code above but it if I add this code:
for(i in 1:length(palette)){
  styles[[i]]$col&lt;-palette[i]
}

names(styles) = nodes$ID

riv&lt;-makeRiver(nodes = nodes, 
               edges =  River_DF, 
               node_styles = styles)

#Generating and saving image to my folder 
png(paste0(study1.graphics, &#39;/S1_PosMood_river.png&#39;), 
    units = &#39;in&#39;, 
    res = 1200, 
    height = 10, 
    width = 10)
riverplot(riv, 
          nodewidth = 3, 
          plot_area = .95)
title(ylab = &#39;Study 1 - Riverplot of Total Variance Decomposition Estimated from Positive Mood Models&#39;)
dev.off()</code></pre>
<p>And here you have it, the final result, which I rotated outside of <code>R</code> to be oriented vertically. The <code>riverplot</code> package will provide a flow that moves from left to right by default.</p>
<div class="figure">
<img src="/img/S1_PosMood_river.png" alt="Figure 4 - Variance Decomposition - As Visually Straightforward as I can make it" />
<p class="caption"><em>Figure 4</em> - Variance Decomposition - As Visually Straightforward as I can make it</p>
</div>
<p>Best of luck applying this approach to your own data. And let’s hope the reviewers of our forthcoming manuscript are sufficiently impressed with this attempt to visually present our model results.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-Bolger1991">
<p>Bolger, Niall, and Elizabeth A. Schilling. 1991. “Personality and the problems of everyday Life: The role of neuroticism in exposure and reactivity to daily stressors.” <em>Journal of Personality</em> 59 (3): 355–86. <a href="https://doi.org/10.1111/j.1467-6494.1991.tb00253.x">https://doi.org/10.1111/j.1467-6494.1991.tb00253.x</a>.</p>
</div>
<div id="ref-Burkner2017">
<p>Bürkner, Paul-Christian. 2017. “brms : An R Package for Bayesian Multilevel Models Using Stan.” <em>Journal of Statistical Software</em> 80 (1). <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.</p>
</div>
<div id="ref-Gelman2013">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian data analysis</em>. New York: CRC Press.</p>
</div>
<div id="ref-Gelman2007">
<p>Gelman, Andrew, and Jennifer Hill. 2007. <em>Data analysis using regression and multilevel/hierarchical models</em>. New York: Cambridge University Press.</p>
</div>
<div id="ref-Jaeger2017">
<p>Jaeger, Byron C., Lloyd J. Edwards, Kalyan Das, and Pranab K. Sen. 2017. “An R2 statistic for fixed effects in the generalized linear mixed model.” <em>Journal of Applied Statistics</em> 44 (6): 1086–1105. <a href="https://doi.org/10.1080/02664763.2016.1193725">https://doi.org/10.1080/02664763.2016.1193725</a>.</p>
</div>
<div id="ref-Nakagawa2016">
<p>Nakagawa, Shinichi, and Holger Schielzeth. 2016. “Coefficient of determination R2 and intra-class correlation coefficient ICC from generalized linear mixed-effects models.” <em>Ecology and Evolution</em>. <a href="https://doi.org/10.1101/095851">https://doi.org/10.1101/095851</a>.</p>
</div>
<div id="ref-Raudenbush2002">
<p>Raudenbush, S. W., and A. S. Bryk. 2002. <em>Hierarchical linear models: Applications and data analysis methods</em>. 2nd ed. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-Rights2018">
<p>Rights, Jason D., and Sonya K. Sterba. 2018. “Quantifying explained variance in multilevel models: An integrative framework for defining R-squared measures.” <em>Psychological Methods</em>. <a href="https://doi.org/10.1037/met0000184">https://doi.org/10.1037/met0000184</a>.</p>
</div>
<div id="ref-Shackman2018b">
<p>Shackman, Alexander J., Melissa D. Stockbridge, Edward P. Lemay, and Andrew S. Fox. 2018. “The psychological and neurobiological bases of dispositional negativity.” In <em>The Nature of Emotion: Fundamental Questions2</em>, edited by Andrew S. Fox, R. C. Lapate, Alexander J. Shackman, and R. J. Davidson, 2nd ed. New York: Oxford University Press.</p>
</div>
<div id="ref-Shackman2016">
<p>Shackman, Alexander J., Melissa Stockbridge, Rachael Tillman, Claire Kaplan, Do Tromp, Andrew Fox, and Matthias Gamer. 2016. “The neurobiology of dispositional negativity and attentional biases to threat: Implications for understanding anxiety disorders in adults and youth.” <em>Journal of Experimental Psychopathology</em> 7 (3): 311–42. <a href="https://doi.org/10.5127/jep.054015">https://doi.org/10.5127/jep.054015</a>.</p>
</div>
<div id="ref-Shackman2016a">
<p>Shackman, Alexander J., Do P.M. Tromp, Melissa D. Stockbridge, Claire M. Kaplan, Rachael M. Tillman, and Andrew S. Fox. 2016. “Dispositional negativity: An integrative psychological and neurobiological perspective.” <em>Psychological Bulletin</em> 142 (12): 1275–1314. <a href="https://doi.org/10.1037/bul0000073">https://doi.org/10.1037/bul0000073</a>.</p>
</div>
<div id="ref-Shackman2018">
<p>Shackman, Alexander J., Jennifer S. Weinstein, Stanton N. Hudja, Conor D. Bloomer, Matthew G. Barstead, Andrew S. Fox, and Edward P. Lemay. 2018. “Dispositional negativity in the wild: Social environment governs momentary emotional experience.” <em>Emotion</em> 18 (5): 707–24. <a href="https://doi.org/10.1037/emo0000339">https://doi.org/10.1037/emo0000339</a>.</p>
</div>
<div id="ref-Weiner2017">
<p>Weiner, January. 2017. <em>Riverplot: Sankey or Ribbon Plots</em>. <a href="https://CRAN.R-project.org/package=riverplot">https://CRAN.R-project.org/package=riverplot</a>.</p>
</div>
</div>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/bayesian-models/">Bayesian Models</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/r/">R</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/statistics/">Statistics</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/multiple-imputation/">Multiple Imputation</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/a-rose-by-any-other-name-statistics-machine-learning-and-ai-part-2-of-3/">A Rose by Any Other Name: Statistics, Machine Learning, and AI (Part 2 of 3)</a></li>
        
        <li><a href="/post/a-rose-by-any-other-name-statistics-machine-learning-and-ai/">A Rose by Any Other Name: Statistics, Machine Learning, and AI (Part 1 of 3)</a></li>
        
        <li><a href="/post/it-s-alive-first-evidence-that-ibi-vizedit-works/">It&#39;s Alive! First Evidence that IBI VizEdit Works</a></li>
        
        <li><a href="/post/rmarkdown-is-the-most-powerful-codebook-maker-you-can-find-for-your-datasets/">RMarkdown is the Most Powerful Codebook Maker You Can Find for Your Datasets</a></li>
        
        <li><a href="/post/interaction-plots-with-continuous-moderators-in-r/">Interaction Plots with Continuous Moderators in R</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 Matthew Barstead &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

