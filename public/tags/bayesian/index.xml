<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian on Dead Reckoning Analytics and Consulting</title>
    <link>/tags/bayesian/</link>
    <description>Recent content in Bayesian on Dead Reckoning Analytics and Consulting</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 19 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/bayesian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Visualizing Variance in Multilevel Models Using the Riverplot Package</title>
      <link>/blog/2019/01/19/2019-01-19-visualizing-variance-in-multilevel-models-using-the-riverplot-package/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/01/19/2019-01-19-visualizing-variance-in-multilevel-models-using-the-riverplot-package/</guid>
      <description>Spurred on by Alex Shackman, I have been working to figure out a good way to visualize different sources of variation in momentary mood. The most common way of visually depicting variance decompositions from the sort of multilevel models we used to analyze our data is a stacked bar plot. So that seemed like a good place to start.
Figure 1. Stacked Barplot of Model Variance Decomposition
 Now, choosing a color scheme that screams “HI I’M A COLOR!</description>
    </item>
    
    <item>
      <title>A Rose by Any Other Name: Statistics, Machine Learning, and AI (Part 2 of 3)</title>
      <link>/blog/2018/12/03/2018-12-03-a-rose-by-any-other-name-statistics-machine-learning-and-ai-part-2-of-3/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/12/03/2018-12-03-a-rose-by-any-other-name-statistics-machine-learning-and-ai-part-2-of-3/</guid>
      <description>In the first post in this series, I described the impetus for this trek through statistical modeling, machine learning and artificial intelligence. I also provided an initial set of comparisons for three different approaches to classification: k-means, k-nearest neighbor, and latent profile analysis (model-based clustering). If you want to check those mini-walkthroughs out click here.
As a reminder, my goal here is to compare and contrast different approaches to data analysis and predictive modeling that are, in my mind, arbitrarily lumped into statistical modeling and machine learing/artificial intelligence categories.</description>
    </item>
    
    <item>
      <title>Bayesian Multilevel Model with Missing Data Complete Workflow (Part 2 of 3)</title>
      <link>/blog/2018/09/03/2018-09-03-bayesian-multilevel-model-with-missing-data-complete-workflow-part-2/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/09/03/2018-09-03-bayesian-multilevel-model-with-missing-data-complete-workflow-part-2/</guid>
      <description>Overview: This is the second post in a three-part blog series I am putting together. If you have not read the first post in this series, you may want to go back and check it out. In this post, I will focus on running and evaluating the imputation model itself, having identified the appropriate covariates that help account for missingness in the first post.
Data Brief Description: The data in question come from a study that involved a one-week ecological momentary assessment (EMA) protocol.</description>
    </item>
    
    <item>
      <title>Bayesian Multilevel Model with Missing Data: Complete Work Flow - Part 1 of 3</title>
      <link>/blog/2018/07/05/2018-07-05-bayesian-multilevel-model-with-missing-data-complete-work-flow/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/07/05/2018-07-05-bayesian-multilevel-model-with-missing-data-complete-work-flow/</guid>
      <description>Overview: This is the first post in a three-part blog series I am putting together. The focus of this initial post is effective exploration of the reasons for missingness in a particular set of data. The second post in the series will focus on running and evaluating the imputation model itself after having identified the appropriate covariates that help account for missingness. The third and final post will be a walkthrough of the final models and their interpretation - including a comparison of the same models using listwise deletion (which is bad unless missingness is small or definitely, 100% completely at random).</description>
    </item>
    
    <item>
      <title>Gaussian Process Imputation/Forecast Models</title>
      <link>/blog/2018/05/21/2018-05-21-gaussian-process-imputation-models/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/05/21/2018-05-21-gaussian-process-imputation-models/</guid>
      <description>A well-established set of problems emerges when attempting to analyze non-stationary univariate time series (i.e., the signal’s mean and/or variance changes over time). A common approach is to impose some stationarity on the data so that certain modeling techniques can provide allow a research to make some predictions (e.g., ARIMA models). The selection of the appropriate assumptions to make when forcing a time series into stationarity is difficult to automate in many circumstances, requiring that a researcher evaluate competing models.</description>
    </item>
    
  </channel>
</rss>